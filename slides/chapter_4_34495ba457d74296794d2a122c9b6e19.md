---
title: Insert title here
key: 34495ba457d74296794d2a122c9b6e19
video_link:
  hls: >-
    https://videos.datacamp.com/transcoded/735_intro_to_python/v6/hls-735_ch4_3.master.m3u8
  mp4: 'https://videos.datacamp.com/raw/735_intro_to_python/v6/735_ch4_3.mp4'
transformations:
  translateX: 50
  translateY: 0
  scale: 1
---

## NumPy: Basic Statistics

```yaml
type: TitleSlide
key: 5d21c4b49f
```

`@lower_third`
name: Hugo Bowne-Anderson
title: Data Scientist at DataCamp

`@script`
A typical first step in analyzing your data,

---

## Data analysis

```yaml
type: FullSlide
key: 32899f8a31
```

`@part1`
- Get to know your data{{1}}

- Little data -> simply look at it{{2}}

- Big data -> ?{{3}}

`@script`
is getting to know your data in the first place. For the NumPy arrays from before, this is pretty easy, because it isn't a lot of data. However, as a data scientist, you'll be crunching thousands, if not millions or billions of numbers.

---

## City-wide survey

```yaml
type: FullSlide
key: df02059657
```

`@part1`
```py
import numpy as np
np_city = ... # Implementation left out
np_city
```{{1}}

```out
array([[1.64, 71.78],
       [1.37, 63.35],
       [1.6 , 55.09],
       ...,
       [2.04, 74.85],
       [2.04, 68.72],
       [2.01, 73.57]])
```{{1}}

`@script`
Imagine you conduct a city-wide survey where you ask 5000 adults about their height and weight. You end up with something like this: a 2D numpy array, which I named np_city, that has 5000 rows, corresponding to the 5000 people, and two columns, corresponding to the height and the weight.

Simply staring at these numbers like a zombie won't give you any insights. What you can do, though, is generate summarizing statistics about your data.

---

## NumPy

```yaml
type: FullSlide
key: d3c991b91f
code_zoom: 90
```

`@part1`
```py
np.mean(np_city[:, 0])
```{{1}}

```out
1.7472
```{{1}}

```py
np.median(np_city[:, 0])
```{{2}}

```out
1.75
```{{2}}

`@script`
Aside from an efficient data structure for number crunching, it happens that NumPy is also good at doing these kinds of things.

For starters, you can try to find out the average height of these 5000 people, with NumPy's mean function. Because it's a function from the NumPy package, don't forget to start with np..

Of course, I first had to do a subsetting operation to get the height column from the 2D array. It appears that on average, people are 1.75 meters tall. What about the median height? This is the height of the middle person if you sort all persons from small to tall. Instead of writing complicated python code to figure this out, you can simply use NumPy's median function:

You can do similar things for the weight column in np_city. Often, these summarizing statistics will provide you with a "sanity check" of your data. If you end up with a average weight of 2000 kilograms, your measurements are most likely incorrect.

Apart from mean and median, there's also other functions,

---

## NumPy

```yaml
type: FullSlide
key: a66131c711
```

`@part1`
```py
np.corrcoef(np_city[:, 0], np_city[:, 1])
```

```out
array([[ 1.     , -0.01802],
       [-0.01803,  1.     ]])
```

```py
np.std(np_city[:, 0])
```{{1}}

```out
0.1992
```{{1}}

- sum(), sort(), ...{{2}}

- Enforce single data type: speed!{{3}}

`@script`
like corrcoeff to check if for example height and weight are correlated,

and std, for standard deviation.

NumPy also features more basic functions, such as sum and sort, which also exist in the basic Python distribution. However, the big difference here is speed. Because NumPy enforces a single data type in an array, it can drastically speed up the calculations.

---

## Generate data

```yaml
type: FullSlide
key: 0c27803967
code_zoom: 80
```

`@part1`
- Arguments for `np.random.normal()` {{1}}
	- distribution mean{{1}}
    - distribution standard deviation{{1}}
    - number of samples{{1}}

```py
height = np.round(np.random.normal(1.75, 0.20, 5000), 2)

weight = np.round(np.random.normal(60.32, 15, 5000), 2)

```{{1}}
```py
np_city = np.column_stack((height, weight))
```{{2}}

`@script`
Just a sidenote here: If you're wondering how I came up with the data in this video: We simulated it with NumPy functions! I sampled two random distributions 5000 times to create the height and weight arrays, and then used column_stack to paste them together as two columns. Another awesome thing that NumPy can do!

Another great tool to get some sense of your data is to visualize it, but that's something for the next course also.

---

## Let's practice!

```yaml
type: FinalSlide
key: c4df18cfc1
```

`@script`
First, head over to the exercises to learn how to explore your NumPy arrays!
