---
title: Insert title here
key: 34495ba457d74296794d2a122c9b6e19
video_link:
  mp3: >-
    https://videos.datacamp.com/mp3/translations/course_735/de-DE/c7733839-4b84-4180-85b1-07f60415c4a4.mp3
---

## NumPy: Grundlegende Statistik

```yaml
type: TitleSlide
key: 5d21c4b49f
```

`@lower_third`
name: Hugo Bowne-Anderson
title: Data Scientist at DataCamp

`@script`
Ein typischer erster Schritt bei der Analyse deiner Daten ist,

---

## Datenanalyse

```yaml
type: FullSlide
key: 32899f8a31
```

`@part1`
- Lerne deine Daten kennen{{1}}

- Wenig Daten –> durch einfaches Betrachten{{2}}

- Viele Daten / Big Data: -> ?{{3}}

`@script`
deine Daten erst mal richtig zu verstehen. Für die NumPy-Arrays von vorhin ist das ziemlich einfach, weil es nicht so viele Daten sind. Als Data Scientist wirst du aber Tausende, wenn nicht sogar Millionen oder Milliarden von Zahlen verarbeiten.


---

## Stadtweite Umfrage

```yaml
type: FullSlide
key: df02059657
```

`@part1`
```py
import numpy as np
np_city = ... # Implementation left out
np_city
```{{1}}

```out
array([[1.64, 71.78],
       [1.37, 63.35],
       [1.6 , 55.09],
       ...,
       [2.04, 74.85],
       [2.04, 68.72],
       [2.01, 73.57]])
```{{1}}

`@script`
Stell dir vor, du machst eine Umfrage in der ganzen Stadt und fragst fünftausend Erwachsene nach ihrer Größe und ihrem Gewicht. Am Ende hast du so was wie das hier: ein zweidimensionales-NumPy-Array, das ich „n-p Unterstrich city“ genannt habe, mit fünftausend Zeilen, die den fünftausend Personen entsprechen, und zwei Spalten, welche die Größe und das Gewicht enthalten.

Einfach wie ein Zombie auf diese Zahlen zu starren, bringt dir keine Erkenntnisse. Was du aber machen kannst, ist, zusammenfassende Statistiken über deine Daten zu erstellen.


---

## NumPy

```yaml
type: FullSlide
key: d3c991b91f
code_zoom: 90
```

`@part1`
```py
np.mean(np_city[:, 0])
```{{1}}

```out
1.7472
```{{1}}

```py
np.median(np_city[:, 0])
```{{2}}

```out
1.75
```{{2}}

`@script`
Abgesehen von einer effizienten Datenstruktur für die Zahlenverarbeitung ist NumPy auch für solche Aufgaben gut geeignet.

Für den Anfang kannst du versuchen, mit der Funktion „mean“ von NumPy die durchschnittliche Größe dieser fünftausend Personen herauszufinden. Da es sich um eine Funktion aus dem NumPy-Paket handelt, darfst du nicht vergessen, „n-p“ als Präfix zu verwenden.

Natürlich muss man zunächst eine Teilmenge mit der Größe aus dem zweidimensionalen-Array bilden. Es sieht so aus, als wären die Leute im Durchschnitt ein-Meter-fünfundsiebzig groß. Wie sieht es mit dem Median der Größe aus? Das ist die Größe der Person in der Mitte, wenn du alle Personen von klein nach groß sortierst. Anstatt komplizierten Python Code zu schreiben, um das herauszufinden, kannst du einfach die Median-Funktion von NumPy verwenden:

Du kannst das Gleiche für die Gewichtsspalte in „n-p Unterstrich city“ machen. Oft helfen dir diese zusammenfassenden Statistiken dabei, deine Daten auf ihre Richtigkeit zu überprüfen. Wenn du am Ende ein Durchschnittsgewicht von zweitausend Kilogramm hast, sind deine Messungen wahrscheinlich nicht richtig.

Neben Mittelwert und Median gibt es noch andere Funktionen,


---

## NumPy

```yaml
type: FullSlide
key: a66131c711
```

`@part1`
```py
np.corrcoef(np_city[:, 0], np_city[:, 1])
```

```out
array([[ 1.     , -0.01802],
       [-0.01803,  1.     ]])
```

```py
np.std(np_city[:, 0])
```{{1}}

```out
0.1992
```{{1}}

- sum(), sort(), ...{{2}}

- Erzwingt einen einzigen Datentyp: Läuft schneller!{{3}}

`@script`
wie beispielsweise „corr co eff“, um mittels Korrelations-Koeffizient prüfen, ob zum Beispiel Größe und Gewicht zusammenhängen,

und die Funktion „s-t-d“ für die Standardabweichung.

NumPy hat auch grundlegendere Funktionen wie „sum“ und „sort“, die auch in der Python Basisversion enthalten sind. Der große Unterschied ist aber die Geschwindigkeit. Weil NumPy in einem Array nur einen einzigen Datentyp zulässt, kann es die Berechnungen stark beschleunigen.


---

## Daten generieren

```yaml
type: FullSlide
key: 0c27803967
code_zoom: 80
```

`@part1`
- Argumente für `np.random.normal()` {{1}}
	- Verteilungsmittelwert{{1}}
    - Verteilungsstandardabweichung{{1}}
    - Anzahl der Proben{{1}}

```py
height = np.round(np.random.normal(1.75, 0.20, 5000), 2)

weight = np.round(np.random.normal(60.32, 15, 5000), 2)

```{{1}}
```py
np_city = np.column_stack((height, weight))
```{{2}}

`@script`
Nur eine kleine Anmerkung am Rande: Falls du dich fragst, wie ich an die Daten in diesem Video gekommen bin: Wir haben sie mit NumPy-Funktionen simuliert! Ich hab fünftausend Mal Proben aus zwei zufälligen Verteilungen genommen, um die Arrays für Größe und Gewicht zu erstellen, und habe anschließend mit „column Unterstrich stack“ alles in zwei Spalten zusammengefügt. Noch so eine coole Sache, die NumPy kann!

Ein weiteres großartiges Werkzeug, um deine Daten besser zu verstehen, ist die Visualisierung. Aber das ist bereits Stoff des nächsten Kurses.


---

## Lass uns üben!

```yaml
type: FinalSlide
key: c4df18cfc1
```

`@script`
Schau dir zunächst die folgenden Übungen an, um zu lernen, wie du deine NumPy-Arrays erkunden kannst!
